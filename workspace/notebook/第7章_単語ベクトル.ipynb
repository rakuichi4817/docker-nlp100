{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e270c0e8-d6d7-4e03-9660-4f0de580d212",
   "metadata": {},
   "source": [
    "# 第7章：単語ベクトル\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3127a4-247a-4cff-892d-5b84081dfc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import bhtsne\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a0a103-1b1d-487a-b493-a29fccc10672",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"data\"          # データを保存するおおもとのディレクトリ\n",
    "CURRENTDIR = \"/workspace/notebook\" # notebookディレクトリへのパス\n",
    "CHAPDIR = os.path.join(DATADIR, \"chapter7\")\n",
    "\n",
    "try:\n",
    "    os.mkdir(CHAPDIR)\n",
    "except:\n",
    "    print(\"作成済み等の理由でディレクトリが作成されませんでした\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d128496-57d3-47ce-a8f1-0f779298f102",
   "metadata": {},
   "source": [
    "## 60. 単語ベクトルの読み込みと表示\n",
    "\n",
    "> Google Newsデータセット（約1,000億単語）での学習済み単語ベクトル（300万単語・フレーズ，300次元）をダウンロードし，”United States”の単語ベクトルを表示せよ．ただし，”United States”は内部的には”United_States”と表現されていることに注意せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071fb6b5-c910-4a0a-9b56-c8627482de8c",
   "metadata": {},
   "source": [
    "### ダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13c67e6-13ca-4742-8371-70c6996ce1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのダウンロード（割と時間かかる）\n",
    "!wget -P $CURRENTDIR/$CHAPDIR \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba9f761-23e6-44e9-b88d-bfc278c5b9c1",
   "metadata": {},
   "source": [
    "### 単語ベクトルの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220b6ac2-6c42-49e4-affe-e619a06e5c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの読み込み（割と時間かかる）\n",
    "model_path = os.path.join(CHAPDIR, \"GoogleNews-vectors-negative300.bin.gz\")\n",
    "model = KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d511be9b-fbdf-40c4-9c83-4b36618bfcdc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model[\"United_States\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e747414-64ff-4a54-9dc5-49816ffe1788",
   "metadata": {},
   "source": [
    "## 61. 単語の類似度\n",
    "\n",
    "> “United States”と”U.S.”のコサイン類似度を計算せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b42305e-ce63-4827-bf14-59aecab0b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.similarity(\"United_States\", \"U.S.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0d7353-799f-4f18-9e5a-666f16a81ecb",
   "metadata": {},
   "source": [
    "## 62. 類似度の高い単語10件\n",
    "\n",
    "> “United States”とコサイン類似度が高い10語と，その類似度を出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a129642c-69e2-4f62-9388-10052f60804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=\"United_States\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f386e3-c16f-4829-94a0-f59f831de106",
   "metadata": {},
   "source": [
    "## 63. 加法構成性によるアナロジー\n",
    "\n",
    "> “Spain”の単語ベクトルから”Madrid”のベクトルを引き，”Athens”のベクトルを足したベクトルを計算し，そのベクトルと類似度の高い10語とその類似度を出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f570519-ea06-4c62-8d34-caa49e73e7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_vec = model[\"Spain\"] - model[\"Madrid\"] + model[\"Athens\"]\n",
    "\n",
    "model.similar_by_vector(result_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc799c9-42e1-4586-94a0-40fb9f01fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=[\"Spain\", \"Athens\"], negative=[\"Madrid\"], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a91a80-c42f-4bd4-8d2e-1095d6c0a830",
   "metadata": {},
   "source": [
    "出力の違いは↓参考。正規化してるかしていないかの違い？\n",
    "\n",
    "https://stackoverflow.com/questions/50275623/difference-between-most-similar-and-similar-by-vector-in-gensim-word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20456aea-5650-4e29-a1b4-7fe18313558b",
   "metadata": {},
   "source": [
    "## 64. アナロジーデータでの実験\n",
    "\n",
    "> 単語アナロジーの評価データをダウンロードし，vec(2列目の単語) - vec(1列目の単語) + vec(3列目の単語)を計算し，そのベクトルと類似度が最も高い単語と，その類似度を求めよ．求めた単語と類似度は，各事例の末尾に追記せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ade4590-a5b0-4088-9842-ae0d2627d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのダウンロード\n",
    "!wget -P $CURRENTDIR/$CHAPDIR \"http://download.tensorflow.org/data/questions-words.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f523b6cb-0499-44b3-b5a6-1c9dc8b8a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy_fpath = os.path.join(CHAPDIR, \"questions-words.txt\")\n",
    "output_fpath = os.path.join(CHAPDIR, \"answer.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be421a13-619c-4e5f-bb03-e83639b2ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input(\"実行にめっちゃ時間かかるけどええか？(y/n)\") == \"y\"\n",
    "    with open(analogy_fpath, \"r\", encoding=\"utf8\")as fr, open (output_fpath, \"w\", encoding=\"utf8\")as fw:\n",
    "        # 各行読み込み\n",
    "        for line in tqdm(fr.readlines()):\n",
    "            if line.startswith(\":\"):\n",
    "                # カテゴリ行はそのまま出力\n",
    "                fw.write(line)\n",
    "            else:\n",
    "                # 単語の組み合わせの場合\n",
    "                words = line.rstrip(\"\\n\").split(\" \")\n",
    "                sim_word, cos = model.most_similar(positive=[words[1], words[2]], \n",
    "                                                   negative=[words[0]], topn=1)[0]\n",
    "                fw.write(\" \".join([line.rstrip(\"\\n\"), sim_word, str(cos)]))\n",
    "                fw.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79f7cc6-2070-4fb2-bcc1-84de5ba8fb2d",
   "metadata": {},
   "source": [
    "## 65. アナロジータスクでの正解率\n",
    "\n",
    "> 64の実行結果を用い，意味的アナロジー（semantic analogy）と文法的アナロジー（syntactic analogy）の正解率を測定せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9760e7c8-a9a6-4f94-bba9-deb9c6dfd50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "\n",
    "sem_tf_list = []\n",
    "syn_tf_list = []\n",
    "\n",
    "with open(output_fpath, \"r\", encoding=\"utf8\")as fr:\n",
    "    flag = \"sem\"\n",
    "    for line in fr:\n",
    "        # 文法的アナロジーのところ\n",
    "        if line.startswith(\":\"):\n",
    "            if line.startswith(\": gram\"):\n",
    "                flag = \"syn\"\n",
    "        else:\n",
    "            sep_line = line.rstrip(\"\\n\").split(\" \")\n",
    "            if flag == \"sem\":\n",
    "                sem_tf_list.append(sep_line[3] == sep_line[4])\n",
    "            elif flag == \"syn\":\n",
    "                syn_tf_list.append(sep_line[3] == sep_line[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20da4607-32e0-44f5-b375-1c4e89f7c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"意味的アナロジー正解率：{sem_tf_list.count(True)/len(sem_tf_list):.3f}\")\n",
    "print(f\"文法的アナロジー正解率：{syn_tf_list.count(True)/len(syn_tf_list):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5db141-3ba9-498b-88c0-43821b33161e",
   "metadata": {},
   "source": [
    "## 66. WordSimilarity-353での評価Permalink\n",
    "\n",
    "> The WordSimilarity-353 Test Collectionの評価データをダウンロードし，単語ベクトルにより計算される類似度のランキングと，人間の類似度判定のランキングの間のスピアマン相関係数を計算せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54d22d-dd00-4235-a5a4-108a4a3b95fd",
   "metadata": {},
   "source": [
    "### データのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93db7428-ae99-48c8-a4ff-20ebbcd85082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存ディレクトリへ移動\n",
    "%cd $CURRENTDIR/$CHAPDIR\n",
    "# ダウンロードと解凍\n",
    "!wget http://www.gabrilovich.com/resources/data/wordsim353/wordsim353.zip\n",
    "!unzip wordsim353.zip\n",
    "!head -5 './combined.csv'\n",
    "# 作業ディレクトリに戻す\n",
    "%cd $CURRENTDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e790f786-14a5-4de5-a6b7-c5a624f87154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語ベクトルで類似度算出\n",
    "fpath = os.path.join(CHAPDIR, \"combined.csv\")\n",
    "\n",
    "result = [] # データ全体用\n",
    "with open(fpath, \"r\", encoding=\"utf8\")as fr:\n",
    "    # 読み飛ばし\n",
    "    next(fr)    \n",
    "    for line in fr:\n",
    "        word1, word2, human_score = line.rstrip(\"\\n\").split(\",\")\n",
    "        sim = model.similarity(word1, word2)\n",
    "        result.append([word1, word2, float(human_score), sim])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e8ce7-e9f1-4315-a679-7517abc69b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# スピアマン相関係数を算出\n",
    "human_scores= np.array(result).T[2]\n",
    "w2v_sims = np.array(result).T[3]\n",
    "\n",
    "result = spearmanr(human_scores, w2v_sims)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a6701d-9acd-4f37-9888-6a8488343f91",
   "metadata": {},
   "source": [
    "## 67. k-meansクラスタリング\n",
    "\n",
    "> 国名に関する単語ベクトルを抽出し，k-meansクラスタリングをクラスタ数k=5として実行せよ．\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18efea8-83ac-4081-bdef-7ba628453a28",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_fpath = os.path.join(CHAPDIR, \"questions-words.txt\")\n",
    "\n",
    "# 国名の取得\n",
    "countries = set()\n",
    "with open(input_fpath, \"r\", encoding=\"utf8\") as f:\n",
    "    mode = None\n",
    "    for line in f:\n",
    "        if \"capital-common-countries\" in line or \"capital-world\" in line:\n",
    "            mode = 1\n",
    "            continue\n",
    "        elif \"currency\" in line or \"gram6-nationality-adjective\" in line:\n",
    "            mode =0\n",
    "            continue\n",
    "        elif line.startswith(\":\"):\n",
    "            mode = None\n",
    "            continue\n",
    "        if mode:\n",
    "            countries.add(line.split(\" \")[mode])\n",
    "countries = list(countries)\n",
    "\n",
    "# 単語ベクトルの取得\n",
    "countries_vec = [model[country] for country in countries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585ad102-e2ce-4b62-8240-ccfe74e196fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75494ec4-618e-4cc9-816c-1c19f4b7c170",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed40663-ac69-4c60-af96-3f5d690b844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(countries_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d5d3a4-caf9-418d-9f39-031978799a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = defaultdict(lambda:list())\n",
    "\n",
    "for label, countrie in zip(kmeans.labels_, countries):\n",
    "    clusters[label].append(countrie)\n",
    "\n",
    "# 表示\n",
    "for label in range(5):\n",
    "    print(f\"■■■ cluster-{label} ■■■\")\n",
    "    print(\", \".join(clusters[label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a802f8-08c9-4adb-9ef5-27447001d116",
   "metadata": {},
   "source": [
    "## 68. Ward法によるクラスタリングPermalink\n",
    "\n",
    "> 国名に関する単語ベクトルに対し，Ward法による階層型クラスタリングを実行せよ．さらに，クラスタリング結果をデンドログラムとして可視化せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46d5fbc-1ae7-4249-b0f5-a2fc08a519de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "Z = linkage(countries_vec, method=\"ward\")\n",
    "dendrogram(Z, labels=countries)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e213fa48-3117-48ff-8c3d-b42774d51049",
   "metadata": {},
   "source": [
    "## 69. t-SNEによる可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eb6f1a-73a7-4d02-9fd6-1d8aaf68510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = bhtsne.tsne(np.array(countries_vec).astype(np.float64), dimensions=2, rand_seed=123)\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.scatter(np.array(embedded).T[0], np.array(embedded).T[1])\n",
    "for (x, y), name in zip(embedded, countries):\n",
    "    plt.annotate(name, (x, y))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1efef20-a688-475e-bc6c-a620ef4afe3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
